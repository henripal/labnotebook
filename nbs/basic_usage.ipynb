{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Notebook: Simple Usage Example\n",
    "\n",
    "This notebook demonstrates how to use labnotebook with randomly generated experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import labnotebook\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first set up our model; it will generate random numbers between 0 and 100 for train accuracy, validation accuracy, and train loss.\n",
    "\n",
    "Our model will have only one \"hyperparameter\": the volatility of the random number generation; this would typically be a dictionnary containing *all* the hyperparameters of your model.\n",
    "\n",
    "Also, we'll break out the generation of each random number into a `for` loop, which obviously doesn't make any sense. Every step of this loop would translate into one step of your optimisation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_desc = {'sigma': .1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to initialize the package by providing it the address of the database you want to use.\n",
    "\n",
    "It will create three tables: `experiments`, `steps`, and `model_params`.\n",
    "\n",
    "- `experiments` is used to store a list of experiments, along with their hyperparameters and final results.\n",
    "\n",
    "- `steps` is used to store the intermediary results for each step of each experiment. This is what you would want to plot if you're monitoring your experiments.\n",
    "\n",
    "- Finally, `model_params` is used to store your model parameters; what you would use to save the weights of your neural network for later inference. This can get pretty big so it's recommended not to save all the parameters at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_url = 'postgres://<username>:<passsword>@localhost/<database_name>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henripal/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "experiments, steps, model_params = labnotebook.initialize(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an Experiment\n",
    "\n",
    "Here, our virtual experiment will generate random numbers for 10 steps.\n",
    "\n",
    "There are only three extra lines of code added to permanently record this experiment in your database and plot it using the web app: `start_experiment`, `step_experiment` and `stop_experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run 6 on GPU 0 at 2018-03-18 14:53:17.418460"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we start the experiment and output it to an 'experiment' variable\n",
    "# we can then pass this experiment to step_experiment and end_experiment\n",
    "experiment = labnotebook.start_experiment(model_desc = model_desc)\n",
    "\n",
    "\n",
    "for experiment_step in range(10):\n",
    "    \n",
    "    # randomly generated validation, training accuracies and losses:\n",
    "    valacc = np.random.normal(0, model_desc['sigma'])\n",
    "    trainacc = np.random.normal(0, model_desc['sigma'])\n",
    "    trainloss = np.random.normal(0, model_desc['sigma'])\n",
    "    \n",
    "    # example 'custom field' that you can add to your tracking\n",
    "    other_variable = experiment_step * 2 - valacc\n",
    "    \n",
    "    # we pass all our indicators to step_experiment\n",
    "    labnotebook.step_experiment(experiment,\n",
    "                                timestep=experiment_step,\n",
    "                                trainloss=trainloss,\n",
    "                                valacc=valacc,\n",
    "                                trainacc=trainacc,\n",
    "                                custom_fields={'goofy_variable': other_variable})\n",
    "    \n",
    "    \n",
    "# we close the experiment and pass all final indicators:\n",
    "labnotebook.end_experiment(experiment,\n",
    "                            final_trainloss=trainloss,\n",
    "                            final_valacc=valacc,\n",
    "                            final_trainacc=trainacc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing our experiments\n",
    "### Through the web app\n",
    "\n",
    "Two steps are needed:\n",
    "- Launch the backend flask API by running from the command line:\n",
    "```\n",
    "start_backend <database_url>\n",
    "```\n",
    "\n",
    "- Navigate to the `labnotebook/frontend` directory and serve its contents, for example by running `python -m http.server`\n",
    "You should see something like this after selecting experiments from the left menu:\n",
    "\n",
    "![](./img/labnotebook.png)\n",
    "\n",
    "You can change what you see, turn live updating on or off, etc... from the `options` menu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Through sqlalchemy ORM commands\n",
    "\n",
    "You essentially have access to *all* your data in a relational database, and can query it in sophisticated ways that are beyond the scope of this notebook. \n",
    "\n",
    "I recommend looking through [sqlalchemy's documentation](http://docs.sqlalchemy.org/en/latest/orm/tutorial.html#querying) , but here are some simple example queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id:  1\tmodel_desc:  {'sigma': 0.1}\n",
      "run id:  2\tmodel_desc:  {'sigma': 0.1}\n",
      "run id:  3\tmodel_desc:  {'sigma': 0.1}\n",
      "run id:  4\tmodel_desc:  {'sigma': 0.1}\n",
      "run id:  5\tmodel_desc:  {'sigma': 0.1}\n",
      "run id:  6\tmodel_desc:  {'sigma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# list all experiments and print some of their properties:\n",
    "\n",
    "experiment_list = labnotebook.session.query(experiments).all()\n",
    "\n",
    "for experiment in experiment_list: \n",
    "    print(\"run id: \", experiment.run_id, end='\\t')\n",
    "    print(\"model_desc: \", experiment.model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.0881643584718841\n",
      "training accuracy:  0.114199389001045\n",
      "training accuracy:  -0.20606842946817\n",
      "training accuracy:  0.00735350586226073\n",
      "training accuracy:  -0.149939680518542\n",
      "training accuracy:  -0.146279798077668\n",
      "training accuracy:  0.0126899091536999\n",
      "training accuracy:  -0.0281140716874202\n",
      "training accuracy:  0.0586363642532856\n",
      "training accuracy:  0.00123095750017543\n"
     ]
    }
   ],
   "source": [
    "# list all steps of experiment #1 and print train accuracies:\n",
    "\n",
    "step_list = labnotebook.session.query(steps).filter(steps.run_id == 4).all()\n",
    "\n",
    "for step in step_list:\n",
    "    print(\"training accuracy: \", step.trainacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 on GPU 0 at 2018-03-18 14:11:50.702179\n",
      "Run 2 on GPU 0 at 2018-03-18 14:11:50.702179\n",
      "Run 3 on GPU 0 at 2018-03-18 14:11:50.702179\n",
      "Run 4 on GPU 0 at 2018-03-18 14:11:50.702179\n",
      "Run 5 on GPU 0 at 2018-03-18 14:52:56.322151\n",
      "Run 6 on GPU 0 at 2018-03-18 14:53:17.418460\n"
     ]
    }
   ],
   "source": [
    "# list all experiments where sigma is greater than 0:\n",
    "import sqlalchemy\n",
    "\n",
    "experiment_list_highsigma = labnotebook.session.query(\n",
    "    experiments).filter(experiments.model_desc['sigma'].astext.cast(sqlalchemy.types.Float) > 0).all()\n",
    "\n",
    "for experiment in experiment_list_highsigma:\n",
    "    print(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in this last example that we're filtering with respect to items inside a dictionary; they are passed as text so we have to cast them to Float to run comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
